{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for mathematics, science and engineering\n",
    "https://scipy.org/\n",
    "\n",
    "## Scipy\n",
    "(pronounced \"Sigh Pie\")\n",
    "\n",
    "Higher level algorithms on top of `numpy`\n",
    "\n",
    "* numerical integration\n",
    "* optimization\n",
    "* interpolation\n",
    "* Signal Processing\n",
    "* Linear Algebra\n",
    "  * with sparse matrices\n",
    "* statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Statistics\n",
    "\n",
    "The [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) package \"_contains a large number of probability distributions as well as a growing library of statistical functions_\". Here we demonstrate how you can extract various statistics from a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can import the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) from [`scikit-learn`](http://scikit-learn.org/stable/index.html)\n",
    "\n",
    "* collected by Ronald Fisher (1936)\n",
    "* contains 50 flower samples\n",
    "* 4 parameters for each sample\n",
    "  * sepal length, sepal width, petal length, petal width\n",
    "* the samples are labeled according to species\n",
    "  * setosa, virginica, versicolor\n",
    "* the raw data is a $50\\times 4$ matrix\n",
    "  * the rows are labeled with $\\{0,1,2\\}$\n",
    "<img width=200 src=\"petal-sepal.jpg\"/>\n",
    "\n",
    "It is often used to test machine learning algorithms, to see if they can guess the species from the size of the perianth measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target names: ['setosa' 'versicolor' 'virginica']\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print('Target names:', iris.target_names)\n",
    "print('Features:', iris.feature_names)\n",
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples can be divided into three classes, according to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "first = iris.data[iris.target == 0]\n",
    "second = iris.data[iris.target == 1]\n",
    "third = iris.data[iris.target == 2]\n",
    "print(len(first), len(second), len(third))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "* Calculate the class-wise mean of the data points (three 4-dimensional vectors)\n",
    "\n",
    "Use `numpy.average`!\n",
    "\n",
    "* Calculate the geometric mean. You won't find a function for that in `numpy`; use `scipy.stats.gmean`.\n",
    "\n",
    "* Calculate the Pearson correlation between\n",
    "  * the sepal width and length\n",
    "  * the petal width and length\n",
    "  * all of the above but for each of the three classes separately\n",
    "\n",
    "Use `scipy.stats.pearsonr` for correlation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.006  3.418  1.464  0.244] [ 5.936  2.77   4.26   1.326] [ 6.588  2.974  5.552  2.026]\n",
      "[ 4.99384106  3.3969062   1.45373856  0.22346247] [ 5.91397936  2.75187353  4.23308089  1.31118738] [ 6.55779452  2.95701356  5.52578887  2.00721413]\n",
      "(-0.10936924995064935, 0.18276521527136649) (0.96275709705096624, 5.776660988495158e-86)\n",
      "(0.74678037326392677, 4.7519865801489557e-10) (0.52591071728282457, 8.7718600119738425e-05) (0.45722781639411292, 0.00084346247237087788)\n",
      "(0.30630821115803558, 0.030507161205929209) (0.78666808852281678, 1.2719157063236543e-11) (0.3221082159003183, 0.022535767279873952)\n"
     ]
    }
   ],
   "source": [
    "cwmean_1 = np.average(first, axis=0)\n",
    "cwmean_2 = np.average(second, axis=0)\n",
    "cwmean_3 = np.average(third, axis=0)\n",
    "print(cwmean_1, cwmean_2, cwmean_3)\n",
    "\n",
    "gmean_1 = stats.gmean(first, axis=0)\n",
    "gmean_2 = stats.gmean(second, axis=0)\n",
    "gmean_3 = stats.gmean(third, axis=0)\n",
    "print(gmean_1, gmean_2, gmean_3)\n",
    "\n",
    "# features: [sep_len, sep_wid, pet_len, pet_wid]\n",
    "corr_sep = stats.pearsonr(iris.data[:, 1], iris.data[:, 0])\n",
    "corr_pet = stats.pearsonr(iris.data[:, 3], iris.data[:, 2])\n",
    "print(corr_sep, corr_pet)\n",
    "\n",
    "corr_sep_1 = stats.pearsonr(first[:, 1], first[:, 0])\n",
    "corr_sep_2 = stats.pearsonr(second[:, 1], second[:, 0])\n",
    "corr_sep_3 = stats.pearsonr(third[:, 1], third[:, 0])\n",
    "print(corr_sep_1, corr_sep_2, corr_sep_3)\n",
    "\n",
    "corr_pet_1 = stats.pearsonr(first[:, 3], first[:, 2])\n",
    "corr_pet_2 = stats.pearsonr(second[:, 3], second[:, 2])\n",
    "corr_pet_3 = stats.pearsonr(third[:, 3], third[:, 2])\n",
    "print(corr_pet_1, corr_pet_2, corr_pet_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear algebra\n",
    "\n",
    "The [`scipy.linalg`](https://docs.scipy.org/doc/scipy/reference/linalg.html) module contains\n",
    "- linear (equation system) solvers\n",
    "- advanced matrix functions (pseudo inverse, etc.)\n",
    "- matrix decomposition functions (eigen-, singular value-, etc.)\n",
    "- special matrix generators\n",
    "- matrix equations solvers\n",
    "- etc.\n",
    "\n",
    "A few examples follow below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear equation systems\n",
    "\n",
    "Solves $A\\cdot x = b$, where $A\\in\\mathbb{R}^{n\\times n}, b\\in \\mathbb{R}^n$ for $x\\in\\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A|b]:\n",
      "[[ 0.   0.5  0.   0.   0.   0.   0.   0.   1. ]\n",
      " [-0.5  0.   0.5  0.   0.   0.   0.   0.   1. ]\n",
      " [ 0.  -0.5  0.   0.5  0.   0.   0.   0.   1. ]\n",
      " [ 0.   0.  -0.5  0.   0.5  0.   0.   0.   1. ]\n",
      " [ 0.   0.   0.  -0.5  0.   0.5  0.   0.   1. ]\n",
      " [ 0.   0.   0.   0.  -0.5  0.   0.5  0.   1. ]\n",
      " [ 0.   0.   0.   0.   0.  -0.5  0.   0.5  1. ]\n",
      " [ 0.   0.   0.   0.   0.   0.  -0.5  0.   1. ]]\n",
      "x: [-8.  2. -6.  4. -4.  6. -2.  8.]\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "\n",
    "A = 0.5*(np.diag(np.ones(7), k=1) - np.diag(np.ones(7), k=-1))\n",
    "b = np.ones(len(A))\n",
    "\n",
    "print('[A|b]:\\n{}'.format(np.concatenate((A, b.reshape(-1,1)), axis=1)))\n",
    "\n",
    "x = linalg.solve(A, b)\n",
    "print('x:', x)\n",
    "\n",
    "# Let's test if the solution is correct\n",
    "assert np.allclose(A.dot(x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least square problem\n",
    "\n",
    "Finds optimal solution, for non-invertible coefficient matrix. Used when the equation system is _overdetermined_: there are more equations than variables:\n",
    "$A\\in\\mathbb{R}^{n\\times k}, b\\in \\mathbb{R}^n$ and $x\\in\\mathbb{R}^k, \\quad n > k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[-1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "b: [-1.         -0.77777778 -0.55555556 -0.33333333 -0.11111111  0.11111111\n",
      "  0.33333333  0.55555556  0.77777778  1.        ]\n",
      "x: [ 1.          1.77777778  2.33333333  2.66666667  2.77777778  2.66666667\n",
      "  2.33333333  1.77777778  1.        ]\n"
     ]
    }
   ],
   "source": [
    "A2 = (np.diag(np.ones(9), k=1) - np.diag(np.ones(10), k=0))[:-1, :].T\n",
    "print('A:\\n{}'.format(A2))\n",
    "b2 = np.linspace(-1, 1, num=len(A2))\n",
    "x2 = linalg.lstsq(A2, b2)[0]\n",
    "print('b:', b2)\n",
    "print('x:', x2)\n",
    "# matplotlib.pyplot.plot(range(1, len(b)+1), b)\n",
    "# matplotlib.pyplot.plot(range(0, len(x)), x)\n",
    "\n",
    "# In this case, the solution is exact.\n",
    "assert np.allclose(A2.dot(x2), b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse matrices\n",
    "\n",
    "Many matrices in practice only have nonzero values in some of their cells; i.e. they are **sparse**. Storing large sparse matrices takes up a lot of memory space unneccesarily. The [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html) module implements memory-efficient sparse matrix classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, memory-efficiency comes at a price. There are several types of sparse matrices, all with specific advantages and disadvantages. A few examples:\n",
    "\n",
    "* Optimized for storage:\n",
    "  * [`coo_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html): coordinate-data tuples\n",
    "* Aimed for incrementally creating sparse matrices:\n",
    "  * [`lil_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html): based on a linked list\n",
    "  * [`dok_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.dok_matrix.html): based on a `dict` of `dict`s\n",
    "* Optimized for arithmetic operations\n",
    "  * [`csr_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html): fast row operations\n",
    "  * [`csc_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html): fast column operations\n",
    "  \n",
    "For further gotchas, see the package and matrix descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "A `csc_matrix` (or `csr_matrix`) is created from three lists: values, row indices and column indices.\n",
    "* below:\n",
    "  * matrix values: `[1, 2, 3, 4]`\n",
    "  * row indices: `[0, 1, 1, 2]`\n",
    "  * col indices: `[1, 0, 2, 1]`\n",
    "* meaning: \n",
    "  * $1$ is at position $(0,1)$\n",
    "  * $2$ is at position $(1,0)$\n",
    "  * $3$ is at position $(1,2)$\n",
    "  * $4$ is at position $(2,1)$\n",
    "  \n",
    "We cannot print the whole sparse matrix; use\n",
    "* `.todense()` to convert it into a dense matrix\n",
    "* `.toarray()` to convert it into an array\n",
    "\n",
    "first; although not recommended if the matrix is huge (why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csc:\n",
      "  (1, 0)\t2.0\n",
      "  (0, 1)\t1.0\n",
      "  (2, 1)\t4.0\n",
      "  (1, 2)\t3.0\n",
      "csc.toarray():\n",
      "[[ 0.  1.  0.]\n",
      " [ 2.  0.  3.]\n",
      " [ 0.  4.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "#from scipy import sparse.linalg\n",
    "csc = sparse.csc_matrix(([1, 2, 3, 4], ([0, 1, 1, 2], [1, 0, 2, 1])), shape=(3,3), dtype=float)\n",
    "print(\"csc:\\n{}\".format(csc))\n",
    "print(\"csc.toarray():\\n{}\".format(csc.toarray()))\n",
    "csc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse linear algebra\n",
    "\n",
    "The `scipy.linalg` package has a sparse equivalent: [`scipy.sprase.linalg`](https://docs.scipy.org/doc/scipy/reference/sparse.linalg.html). Use the latter for sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "* Solve the linear equation system you did above with numpy.\n",
    "  * call the variables `As`, `bs`, `xs` to avoid accidentally overriding the originals\n",
    "  * use `scipy.sparse.diags` instead of `numpy.diag`\n",
    "  * note that the signatures of the sparse functions might be different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As:\n",
      "[[ 0.   0.5  0.   0.   0.   0.   0.   0. ]\n",
      " [-0.5  0.   0.5  0.   0.   0.   0.   0. ]\n",
      " [ 0.  -0.5  0.   0.5  0.   0.   0.   0. ]\n",
      " [ 0.   0.  -0.5  0.   0.5  0.   0.   0. ]\n",
      " [ 0.   0.   0.  -0.5  0.   0.5  0.   0. ]\n",
      " [ 0.   0.   0.   0.  -0.5  0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0.   0.  -0.5  0.   0.5]\n",
      " [ 0.   0.   0.   0.   0.   0.  -0.5  0. ]]\n",
      "bs: [ 1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "xs: [-8.  2. -6.  4. -4.  6. -2.  8.]\n"
     ]
    }
   ],
   "source": [
    "# Create As and bs\n",
    "As = 0.5*(sparse.diags(np.ones(7), offsets=1) - sparse.diags(np.ones(7), offsets=-1))\n",
    "bs = np.ones(8)\n",
    "\n",
    "print('As:\\n{}'.format(As.toarray()))\n",
    "print('bs:', bs)\n",
    "\n",
    "xs = sparse.linalg.spsolve(As, bs)\n",
    "# Solve the equation system!\n",
    "print('xs:', xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition example\n",
    "\n",
    "Below we run sparse [singular value decomposition](https://en.wikipedia.org/wiki/Singular-value_decomposition) on `As`:\n",
    "* first, we obtain the component matrices $U, d, V^*$ (note that these won't be sparse)\n",
    "* then, we reconstruct the original matrix from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full sparse SVD:\n",
      "[[ 0.          0.47400494  0.         -0.04885474  0.         -0.06582181\n",
      "   0.         -0.0748498 ]\n",
      " [-0.47400494  0.          0.52285967  0.          0.01696707  0.\n",
      "   0.00902799  0.        ]\n",
      " [ 0.         -0.52285967  0.          0.45703787  0.         -0.05788273\n",
      "   0.         -0.06582181]\n",
      " [ 0.04885474  0.         -0.45703787  0.          0.53188766  0.\n",
      "   0.01696707  0.        ]\n",
      " [ 0.         -0.01696707  0.         -0.53188766  0.          0.45703787\n",
      "   0.         -0.04885474]\n",
      " [ 0.06582181  0.          0.05788273  0.         -0.45703787  0.\n",
      "   0.52285967  0.        ]\n",
      " [ 0.         -0.00902799  0.         -0.01696707  0.         -0.52285967\n",
      "   0.          0.47400494]\n",
      " [ 0.0748498   0.          0.06582181  0.          0.04885474  0.\n",
      "  -0.47400494  0.        ]]\n",
      "\n",
      "Sparse SVD, first 2 singular values:\n",
      "[[ 0.          0.09181687  0.         -0.1406716   0.          0.12370453\n",
      "   0.         -0.04885474]\n",
      " [-0.09181687  0.          0.23248847  0.         -0.26437614  0.\n",
      "   0.17255927  0.        ]\n",
      " [ 0.         -0.23248847  0.          0.35619301  0.         -0.31323087\n",
      "   0.          0.12370453]\n",
      " [ 0.1406716   0.         -0.35619301  0.          0.40504774  0.\n",
      "  -0.26437614  0.        ]\n",
      " [ 0.          0.26437614  0.         -0.40504774  0.          0.35619301\n",
      "   0.         -0.1406716 ]\n",
      " [-0.12370453  0.          0.31323087  0.         -0.35619301  0.\n",
      "   0.23248847  0.        ]\n",
      " [ 0.         -0.17255927  0.          0.26437614  0.         -0.23248847\n",
      "   0.          0.09181687]\n",
      " [ 0.04885474  0.         -0.12370453  0.          0.1406716   0.\n",
      "  -0.09181687  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def reconstruct_svd(M, k=None):\n",
    "    if k is None:\n",
    "        U, d, Vh = sparse.linalg.svds(M)\n",
    "    else:\n",
    "        U, d, Vh = sparse.linalg.svds(M, k)\n",
    "    M_rec = U.dot(np.diag(d).dot(Vh))\n",
    "    # Set small elements to zero\n",
    "    M_rec[np.abs(M_rec) < 1e-15] = 0\n",
    "    return M_rec\n",
    "\n",
    "print(\"Full sparse SVD:\\n{}\\n\".format(reconstruct_svd(A)))\n",
    "print(\"Sparse SVD, first 2 singular values:\\n{}\".format(reconstruct_svd(A, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-term matrix decomposition\n",
    "\n",
    "The [following file](http://sandbox.hlt.bme.hu/~gaebor/ea_anyag/python_nlp/movies.txt) contains (preprocessed) movie descriptions, from [CMU Movie Corpus](http://www.cs.cmu.edu/~ark/personas/).\n",
    "* One movie per line\n",
    "* `\"title\\tdescription\\n\"` format\n",
    "* description is space separated list of words, tokenized\n",
    "* Some of its UTF8  characters are broken, so we have to read it binary (byte array)\n",
    "\n",
    "Download the file and put it in the same folder, as your notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.\n",
    "* Make a vocabulary of titles (`dict` keyed by titles)\n",
    "  * Each movie title should get a unique ID, from 0 to the number of movies (~39k)\n",
    "  * call this `movie_to_id`\n",
    "* Make a vocabulary of words (`dict` keyed by words)\n",
    "  * Each word, which occurs in any of the  descriptions, should get a unique ID, from 0 to the number of unique words (~182k)\n",
    "* Also make reverse vocabularies (movie id to movie title, word id to the word itself)\n",
    "  * for movies, call it `id_to_movie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movies.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0c6d6054ac37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmovie_descriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"movies.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmovie_descriptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movies.txt'"
     ]
    }
   ],
   "source": [
    "movie_descriptions = {}\n",
    "with open(\"movies.txt\", \"rb\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        title, description = line.strip().split(b'\\t')\n",
    "        movie_descriptions[title] = description.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(movie_descriptions))\n",
    "print(b\" \".join(movie_descriptions[b\"The Matrix\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.\n",
    "Make a sparse matrix defined in the following way:\n",
    "* $a_{i,j} = $ number of times the word with ID $j$ was mentioned in the movie with ID $i$\n",
    "* the rows of the matrix are movies\n",
    "* columns are words\n",
    "* use `float32` representation (`dtype`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.\n",
    "* Perform a sparse SVD with k=40 and store the left singular vectors as rows (`U`) and the right singular vectors as columns (`Vh`).\n",
    "* normalize the vectors (rows of `U` and columns of `Vh`) to unit length.\n",
    "* $U\\in\\mathbb{R}^{\\text{~39k}\\times 40}$\n",
    "* $Vh\\in\\mathbb{R}^{40\\times \\text{~182k}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.\n",
    "Write a function, which searches the closest vectors to a given vector.\n",
    "* Use the global variable `U`\n",
    "* the input is a vector $v$ and a number $k\\in\\mathbb{N}$.\n",
    "* return the row indices of the $k$ closest vector to $v$ in $U$!\n",
    "\n",
    "Try to use vectorization and [`numpy.argpartition`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argpartition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closests(v, k=1):\n",
    "    return list(range(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "closests(np.ones(len(Vh)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can search similar movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print([id_to_movie[i] for i in closests(U[movie_to_id[b\"Monsters, Inc.\"]], 5)])\n",
    "print([id_to_movie[i] for i in closests(U[movie_to_id[b\"Popeye\"]], 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even mixture of movies by adding _\"movie vectors\"_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[id_to_movie[i] for i in closests(U[movie_to_id[b\"Popeye\"]] + U[movie_to_id[b\"Monsters, Inc.\"]], 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
